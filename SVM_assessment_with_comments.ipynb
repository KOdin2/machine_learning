{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM assessment with comments",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/rGCbPSW81RQT2r3Q5EhT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOdin2/machine_learning/blob/main/SVM_assessment_with_comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyvgsejzKZ6"
      },
      "source": [
        "**SVM**\n",
        "\n",
        "This code up is used to classify a dataset whose labels are a binary (either 1 and 0) a range of hyperparameters are tried. The best hyperparameters are used to calculate the Gini importance of each feature. The Gini importance allows us to remove features with a rank of 0, which means the model does not find it useful.\n",
        "\n",
        "**Note:** A uploaded dataset must have one column labeled \"Label\" with the row values as a 1 or 0 otherwise this code will not work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9GmNtOheAuq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1540da-817a-43f0-e160-52ee47393cfd"
      },
      "source": [
        "\"\"\" Import libraries \"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import csv\n",
        "\n",
        "\n",
        "\"\"\" Import sklearn specific functions \"\"\"\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\"\"\" Import excel writer to allow excel notebooks to be written \"\"\"\n",
        "!pip install xlsxwriter\n",
        "import xlsxwriter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-1.4.5-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 102 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 122 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 133 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 143 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 149 kB 7.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-1.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLbqdztR0RWI"
      },
      "source": [
        "The following code is used to upload as many files as you want to be classified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DOLCNaj8eLnw",
        "outputId": "399ab5ee-526d-4a1e-addd-0693ba901d40"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-70d86dbb-20f9-4880-a526-5f7724f8f003\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-70d86dbb-20f9-4880-a526-5f7724f8f003\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SSteel_25-75WF_dataset.csv to SSteel_25-75WF_dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXLnjg8sRn8S"
      },
      "source": [
        "The best measurements to use for classification are:\n",
        "\n",
        "* precision\n",
        "* recall\n",
        "* accuracy\n",
        "* f1\n",
        "* roc_auc\n",
        "\n",
        "Be careful with precision and recall as you can achieve 100% of one and have a really low other. F1 score is the harmoninc mean of precision and recall therefore should be used instread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXdLwan805nQ"
      },
      "source": [
        "**calculate_cross_validation_value**\n",
        "\n",
        "Is used to fond the largest fold value possible for CV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcacs_-Qj9jy"
      },
      "source": [
        "def calculate_cross_validation_value(y_train):\n",
        "  \"\"\" aqurie the smallest number group of labels and return this for CV \"\"\"\n",
        "  arr = y_train.to_numpy()\n",
        "  bin_arr = np.bincount(arr)\n",
        "  return bin_arr.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgbNNePh1kyc"
      },
      "source": [
        "**grid_search_RF_function**\n",
        "\n",
        "This function is used to perfrom a grid search of defined hyperparameters\n",
        "\n",
        "Once complete this model will the models best parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzSWN1xihqF_"
      },
      "source": [
        "def grid_search_function(x_train, y_train, Varible_list_1 , number_of_cv_folds):\n",
        "\n",
        "  \"\"\" Initalise the SVM model with the best hyperparameters and setup the MinMaxscaler() \"\"\"\n",
        "  model = SVC(random_state=0)  \n",
        "  min_max = MinMaxScaler()\n",
        "  \n",
        "  \"\"\" Setup the pipeline to perform scaling and model \"\"\"\n",
        "  pipe = Pipeline(steps = [\n",
        "                               (\"min_max\" , min_max ),\n",
        "                               \n",
        "                               (\"model\" , model )\n",
        "                               \n",
        "  ])\n",
        "\n",
        "  \"\"\" Set up the parameters for grid search with desired varibles for it to try \"\"\"\n",
        "  param_grid = [\n",
        "        {'model__kernel': ['linear', 'rbf', 'poly'], 'model__C': Varible_list_1, }\n",
        "  ]\n",
        "\n",
        "  \"\"\" Assign the scoring type for grid search \"\"\"\n",
        "  scoring_type = 'f1'\n",
        "  \n",
        "  \"\"\" Set up the gridsearch using defined varible \"\"\"\n",
        "  grid_search = GridSearchCV(estimator= pipe, param_grid= param_grid,  cv= number_of_cv_folds , scoring=scoring_type,  return_train_score=True, n_jobs=-1) #n_jobs=-1 will use all avaliable processors avaliable\n",
        "\n",
        "  \"\"\" Perfrom grid search with the x and y train data \"\"\"\n",
        "  grid_search.fit(X= x_train, y= y_train)\n",
        "\n",
        "  \"\"\" Aquire the best score and round to 4 decimal places and print the best parameters\"\"\"\n",
        "  best_accuracy = round(grid_search.best_score_,4)\n",
        "  print(\"[INFO] Best score: \" + str(best_accuracy) + \" with parameters: \"  + str(grid_search.best_params_) )\n",
        "\n",
        "  \"\"\" Create a list of the best results from the Gridsearch \"\"\"\n",
        "  best_model_details = ([ \"SVM\",\n",
        "                        scoring_type,\n",
        "                        best_accuracy,\n",
        "                        grid_search.best_params_['model__kernel'],\n",
        "                        grid_search.best_params_['model__C'],\n",
        "                        str(number_of_cv_folds.n_splits),\n",
        "                      \n",
        "  ])\n",
        "\n",
        "  \"\"\" Resturn the best model results and the parameters that will be used for feature reduction \"\"\" \n",
        "  return best_model_details, grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvbDluQL2nAQ"
      },
      "source": [
        "**graph_important_features** \n",
        "\n",
        "Is used to graph the importance of the features\n",
        "\n",
        "As it is a function the values can be changed to make the graph clear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUlM27FscHZJ"
      },
      "source": [
        "def graph_important_features(model, x_train_df):\n",
        "\n",
        "  print(\"Feature importances of the input data obtained from (feature_importances_) for SVM\")\n",
        "\n",
        "  importance = np.abs(model.feature_importances_)\n",
        "  feature_names = np.array(x_train_df.columns)\n",
        "\n",
        "  f, ax = plt.subplots(figsize=(30,5))\n",
        "  plt.bar(height=importance, x=feature_names, )\n",
        "\n",
        "  plt.xticks(rotation='vertical', fontsize = 16)\n",
        "  plt.yticks(fontsize = 16)\n",
        "\n",
        "  plt.xlabel(\"Feature\", fontsize = 20)\n",
        "  plt.ylabel(\"Gini importance\", fontsize = 20)\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w86ZaW6N2ym1"
      },
      "source": [
        "**best_model_test**\n",
        "\n",
        "THis functions uses the best hyperparameters and the reduced dataset to perform cross validation.\n",
        "\n",
        "This function then returns the results and are used as the final result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2_pnMoZlrEM"
      },
      "source": [
        "def best_model_test(x_train, y_train, number_of_cv_folds, best_paramater):\n",
        "\n",
        "  \"\"\" Initalise the SVM model with the best hyperparameters and setup the MinMaxscaler() \"\"\"\n",
        "  model = SVC(random_state=0, kernel = best_paramater['model__kernel'], C = best_paramater['model__C'])  \n",
        "  min_max = MinMaxScaler()\n",
        "  \n",
        "  \"\"\" Setup the pipeline to perform scaling and model \"\"\"\n",
        "  pipe = Pipeline(steps = [\n",
        "                               (\"min_max\" , min_max ),\n",
        "                               \n",
        "                               (\"model\" , model )\n",
        "                               \n",
        "  ])\n",
        "\n",
        "  \"\"\" Use cross_val_predict to perform cross validation and get the predicted labels \"\"\"\n",
        "  y_train_pred = cross_val_predict(pipe, x_train, y_train, cv=number_of_cv_folds)\n",
        "\n",
        "  \"\"\" Use the labels to produce a confusion matrix \"\"\"\n",
        "  conf = confusion_matrix(y_train, y_train_pred)\n",
        "  print(conf)\n",
        "\n",
        "  \"\"\" Calcualte the accuracies to .4dp which are then printed\"\"\"\n",
        "  f1        = round(f1_score(y_train, y_train_pred), 4)\n",
        "  precision = round(precision_score(y_train, y_train_pred), 4)\n",
        "  recall    = round(recall_score(y_train, y_train_pred), 4)\n",
        "\n",
        "  print(\"F1 score\\tPurity\\t\\tRecovery\")\n",
        "  print(str(f1) + \"\\t\\t\" + str(precision) + \"\\t\\t\" + str(recall) + \"\\n\\n\")\n",
        "    \n",
        "  \"\"\" Write the actual labels and predicted labels to a list. Work out whether the preidction was correct, if so write correct. This is for easy reference \"\"\"\n",
        "  predictions_vs_acutal = []\n",
        "  for index, row_data in enumerate(y_train):  \n",
        "      if y_train[index] == y_train_pred[index]:\n",
        "        correct_str = \"Correct\"\n",
        "      else:\n",
        "        correct_str = \"Incorrect\"\n",
        "      predictions_vs_acutal.insert(index, [y_train[index], y_train_pred[index], correct_str]   )\n",
        "\n",
        "\n",
        "  \"\"\" Create a list that has the accuracy results of the best model \"\"\"\n",
        "  model_check = ([str(f1), str(precision), str(recall), str(conf), str(len(x_train.columns)),  str(number_of_cv_folds.n_splits)])\n",
        "\n",
        "\n",
        "  return predictions_vs_acutal, model_check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZr1_8EB4pIG"
      },
      "source": [
        "Headers used for the exported CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo0UkgDGy7iV"
      },
      "source": [
        "def write_results_to_excel (file_name, grid_search_list, model_check, predictions_vs_acutal):\n",
        "\n",
        "  \"\"\" Create headers used for the output file \"\"\"\n",
        "  header = [\"Algorithm\", \"Scoring type\", \"Score\", \"kernel\",  \"C\", \"Stratified KFold splits\"]\n",
        "  model_check_header = [\"F1 score\", \"Purity\", \"Recovery\", \"Confusion matrix\", \"Number of inputs\", \"Stratified KFold splits\"]\n",
        "  predicion_header = [\"Label\" , \"Prediction\", \"Result\"]\n",
        "\n",
        "  \"\"\"Create the workbook \"\"\"\n",
        "  workbook = xlsxwriter.Workbook(str(file_name) + '_svm.xlsx')\n",
        "  worksheet = workbook.add_worksheet(\"SVM\")\n",
        "\n",
        "  \"\"\" Wrtie the Grid search results \"\"\"\n",
        "  worksheet.write(0, 0, \"Grid search results\")\n",
        "  for row_num, row_data in enumerate(header):\n",
        "    worksheet.write(1, row_num, row_data) \n",
        "  row = 2\n",
        "  for row_num, row_data in enumerate(grid_search_list):\n",
        "      for col_num, col_data in enumerate(row_data):\n",
        "          worksheet.write(row, col_num, str(col_data))\n",
        "      row+=1\n",
        "  row+=1\n",
        "\n",
        "  \"\"\" Write the best model results for final CV test with reduced dataset\"\"\"\n",
        "  worksheet.write(row, 0, \"Best model testing result\")\n",
        "  row+=1\n",
        "  for row_num, row_data in enumerate(model_check_header):\n",
        "    worksheet.write(row, row_num, row_data)\n",
        "  row +=1\n",
        "  for row_num, row_data in enumerate(model_check):\n",
        "    worksheet.write(row, row_num, row_data) \n",
        "  row +=2\n",
        "\n",
        "  \"\"\" Write the predicted values againest actual \"\"\"\n",
        "  worksheet.write(row, 0, \"Prediction results for the best model\")\n",
        "  row +=1 \n",
        "  for row_num, row_data in enumerate(predicion_header):\n",
        "    worksheet.write(row, row_num, row_data) \n",
        "  row+=1\n",
        "\n",
        "  for row_num, row_data in enumerate(predictions_vs_acutal):\n",
        "      for col_num, col_data in enumerate(row_data):\n",
        "          worksheet.write(row, col_num, str(col_data))\n",
        "      row+=1\n",
        "\n",
        "  \"\"\" Close the workboot and download\"\"\"\n",
        "  workbook.close()\n",
        "  files.download(str(file_name) + '_svm.xlsx') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "sugsesBVDuLK",
        "outputId": "c20165bc-ad23-447e-c6e2-837d38a87915"
      },
      "source": [
        "print(\"[INFO] CODE START\")\n",
        "\n",
        "\"\"\" Loop through all uploaded files\"\"\"\n",
        "for file_name in uploaded:\n",
        "    grid_search_list = []  \n",
        "    reduction_mode = False\n",
        "\n",
        "    \"\"\" Convert the uploaded .csv file to a dataframe \"\"\"\n",
        "    print(\"[INFO] File uploaded: \" +str(file_name))\n",
        "    loaded_file = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "\n",
        "    \"\"\" Create the x and y train datasets\"\"\"\n",
        "    x_train  = loaded_file.drop(['Label'], axis='columns')\n",
        "    y_train     = loaded_file.Label\n",
        "\n",
        "    \"\"\" Calculate the largest of number of fold for StratifiedKfold cross-vaildation\"\"\"\n",
        "    number_of_cv_folds = StratifiedKFold(calculate_cross_validation_value(y_train)) #This function can be changed to a int if a dataset is large as it will take long to run, e.g. 10\n",
        "    print(\"[INFO] Number of CV folds: \" + str(number_of_cv_folds.n_splits))\n",
        "\n",
        "    \"\"\" Perform Gird search for the best hyperparameters and appended results to a list\"\"\"\n",
        "    print(\"[INFO] Finding best model parameters\")\n",
        "    grid_search_result, best_paramater = grid_search_function(x_train, y_train, [0.01, 0.1, 1, 10, 100], number_of_cv_folds)   \n",
        "    grid_search_list.append(grid_search_result)\n",
        "\n",
        "    \"\"\" Using the best parameters and reduced dataset aquire the accuracy results and preductions \"\"\"\n",
        "    print(\"[INFO] Final cross-fold valudation test using the best parameters\")\n",
        "    predictions_vs_acutal, model_check = best_model_test(x_train, y_train, number_of_cv_folds, best_paramater,)\n",
        "    \n",
        "    \"\"\" Write all the results of the .csv file to an excel work book \"\"\"\n",
        "    write_results_to_excel(file_name, grid_search_list, model_check, predictions_vs_acutal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] CODE START\n",
            "[INFO] File uploaded: SSteel_25-75WF_dataset.csv\n",
            "[INFO] Number of CV folds: 14\n",
            "[INFO] Finding best model parameters\n",
            "[INFO] Best score: 0.9286 with parameters: {'model__C': 0.01, 'model__kernel': 'poly'}\n",
            "[INFO] Final cross-fold valudation test using the reduced input data and best parameters\n",
            "[[27  0]\n",
            " [ 1 13]]\n",
            "F1 score\tPurity\t\tRecovery\n",
            "0.963\t\t1.0\t\t0.9286\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d75cdb03-af88-4f45-970c-e5ad2fa3f1b8\", \"SSteel_25-75WF_dataset.csv_svm.xlsx\", 6137)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}